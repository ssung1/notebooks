{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\jojo\\jupyter\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\jojo\\jupyter\\lib\\site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jojo\\jupyter\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jojo\\jupyter\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\jojo\\jupyter\\lib\\site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jojo\\jupyter\\lib\\site-packages (from matplotlib) (8.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\jojo\\jupyter\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\jojo\\jupyter\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\jojo\\jupyter\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\jojo\\jupyter\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\jojo\\jupyter\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\jojo\\jupyter\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\jojo\\jupyter\\lib\\site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\jojo\\jupyter\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jojo\\jupyter\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\jojo\\jupyter\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we will try a \"true\" linear training set.\n",
    "\n",
    "|x  |y  |\n",
    "|---|---|\n",
    "|1  |3  |\n",
    "|5  |11 |\n",
    "|2  |5  |\n",
    "\n",
    "At this point, we are still using a single value of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = np.array([1, 5, 2])\n",
    "training_y = np.array([3, 11, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See previous notebook for a simpler example.  For our current example, however, we have $\\theta_0$ and $\\theta_1$, so we need to calculate our hypothesis differently.\n",
    "\n",
    "Training data looks like \n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "1 \\\\\n",
    "5 \\\\\n",
    "2 \\\\\n",
    "\\end{vmatrix}\n",
    "$$\n",
    "\n",
    "We want to pad it with a 1 so that the number of input variables (in our case, 1) equals the number of thetas (2).  The number of thetas is always 1 more than the number of input variables.  Don't get confused -- we have only one input variable for every training sample; however, we do have multiple training samples.  Refer to our notation guide from the previous example:\n",
    "   - $m$ is the number of training samples\n",
    "   - $y$ is the actual value of training sample for a given $x$\n",
    "   - $i$ is the index of the training sample\n",
    "   - $x^{(i)}$ is the $x$ of the the training sample of index $i$\n",
    "   - $j$ is the index of the input variable\n",
    "   - $n$ is the number of input variabls per training sample\n",
    "\n",
    "In this example, $n$ is 1.\n",
    "\n",
    "Once we pad the 1, we will have this training data:\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "1 \\ \\ \\ 1 \\\\\n",
    "1 \\ \\ \\ 5 \\\\\n",
    "1 \\ \\ \\ 2 \\\\\n",
    "\\end{vmatrix}\n",
    "$$\n",
    "\n",
    "Our hypothesis is calculated as:\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "1\\theta_0 + 1\\theta_1 \\\\\n",
    "1\\theta_0 + 5\\theta_1 \\\\\n",
    "1\\theta_0 + 2\\theta_1 \\\\\n",
    "\\end{vmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want\n",
    "#    theta0 * x0 + theta1 * x1\n",
    "# (and remember x0 is set to 1 to simplify calculation)\n",
    "def hypothesis_theta(training_x, theta):\n",
    "    # training_x looks like 1, 5, 2\n",
    "\n",
    "    # first we pad the 1s\n",
    "    size_of_sample = training_x.size\n",
    "    padding = np.ones(size_of_sample)    \n",
    "    padded = np.array([padding, training_x])\n",
    "    \n",
    "    # but we want it in a different orientation\n",
    "    training_sample = padded.T\n",
    "    return training_sample @ theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will repeat some of the functions from previous example (with slight modifications):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_alpha = 0.1\n",
    "acceptable_cost = 0.01\n",
    "max_iterations = 100\n",
    "\n",
    "def cost(hypothesis, training_y):\n",
    "    return np.sum((hypothesis - training_y) ** 2) / 2\n",
    "\n",
    "def sum_of_difference(hypothesis, training_y):\n",
    "    np.sum(hypothesis - training_y)\n",
    "\n",
    "def gradient_descent(theta, training_y):\n",
    "    hypothesis = hypothesis_theta(training_x, theta)\n",
    "    sum_of_difference = sum_of_difference(hypothesis, training_y)\n",
    "    adjustment = training_x * sum_of_difference\n",
    "    return theta - learning_rate_alpha * sum_of_difference(hypothesis_theta(training_x, theta), training_y)\n",
    "\n",
    "def find_minimum():\n",
    "    theta = np.array([0, 0])\n",
    "    iteration = 0\n",
    "    acceptable_cost = 0.001\n",
    "    current_cost = cost(hypothesis_theta(theta))\n",
    "    while current_cost > acceptable_cost and iteration < max_iterations:\n",
    "        theta = gradient_descent(theta)\n",
    "        current_cost = cost(hypothesis_theta(theta))\n",
    "        print((theta, current_cost))\n",
    "        iteration += 1\n",
    "    return (theta, cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through one round of gradient descent just to make sure it makes sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_round_0 = np.array([0, 0])\n",
    "hypothesis_round_0 = hypothesis_theta(training_x, theta_round_0)\n",
    "hypothesis_round_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.5"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_round_0 = cost(hypothesis_round_0, training_y)\n",
    "cost_round_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.sum_of_difference(hypothesis, training_y)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_of_difference_round_0 = sum_of_difference(hypothesis_round_0, training_y)\n",
    "sum_of_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
